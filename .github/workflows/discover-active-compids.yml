name: Discover active comp IDs (daily)

on:
  workflow_dispatch:
  schedule:
    - cron: "12 0 * * *"  # daily at 00:12 UTC

permissions:
  contents: write

jobs:
  discover:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # we will base the 'data' branch on origin/data

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python deps (selenium + bs4)
        run: |
          python -m pip install --upgrade pip
          pip install selenium beautifulsoup4

      # Chrome + matching ChromeDriver
      - id: setup-chrome
        uses: browser-actions/setup-chrome@v2
        with:
          chrome-version: stable
          install-dependencies: true
          install-chromedriver: true

      - name: Export CHROME_BIN
        run: echo "CHROME_BIN=${{ steps.setup-chrome.outputs.chrome-path }}" >> $GITHUB_ENV

      - name: Run discoverer (headless)
        run: |
          mkdir -p server/data
          python scraper/discover_active_compids.py \
            --range "1-30" --skip "72,73,108,114" \
            --out server/data/active_comp_ids.json -v

      # âœ… Publish only the active_comp_ids.json, preserving the rest of the data branch
      - name: Publish active_comp_ids.json to data branch
        run: |
          git config user.name "github-actions"
          git config user.email "actions@github.com"

          git fetch origin data || true
          if git rev-parse --verify origin/data >/dev/null 2>&1; then
            git checkout -B data origin/data
          else
            git checkout -B data
          fi

          mkdir -p server/data
          git add -f server/data/active_comp_ids.json
          git commit -m "discover: active comp IDs $(date -u +'%Y-%m-%dT%H:%M:%SZ')" || echo "No changes"
          git push origin data
